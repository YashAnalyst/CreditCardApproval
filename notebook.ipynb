{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"3"},"tags":["sample_code"]},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Load dataset\n","cc_apps = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n","\n","# Inspect data\n","cc_apps.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"3"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","import pandas as pd\n","\n","def test_cc_apps_exists():\n","    assert \"cc_apps\" in globals(), \\\n","        \"The variable cc_apps should be defined.\"\n","        \n","def test_cc_apps_correctly_loaded():\n","    correct_cc_apps = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n","    try:\n","        pd.testing.assert_frame_equal(cc_apps, correct_cc_apps)\n","    except AssertionError:\n","        assert False, \"The variable cc_apps should contain the data as present in datasets/cc_approvals.data.\""]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"10"},"tags":["sample_code"]},"outputs":[],"source":["# Print summary statistics\n","cc_apps_description = cc_apps.describe()\n","print(cc_apps_description)\n","\n","print('\\n')\n","\n","# Print DataFrame information\n","cc_apps_info = cc_apps.info()\n","print(cc_apps_info)\n","\n","print('\\n')\n","\n","# Inspect missing values in the dataset\n","cc_apps.tail(17)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"10"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","def test_cc_apps_description_exists():\n","    assert \"cc_apps_description\" in globals(), \\\n","        \"The variable cc_apps_description should be defined.\"\n","\n","def test_cc_apps_description_correctly_done():\n","    correct_cc_apps_description = cc_apps.describe()\n","    assert str(correct_cc_apps_description) == str(cc_apps_description), \\\n","        \"cc_apps_description should contain the output of cc_apps.describe().\"\n","    \n","def test_cc_apps_info_exists():\n","    assert \"cc_apps_info\" in globals(), \\\n","        \"The variable cc_apps_info should be defined.\"\n","\n","def test_cc_apps_info_correctly_done():\n","    correct_cc_apps_info = cc_apps.info()\n","    assert str(correct_cc_apps_info) == str(cc_apps_info), \\\n","        \"cc_apps_info should contain the output of cc_apps.info().\""]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"dc":{"key":"17"},"tags":["sample_code"]},"outputs":[],"source":["# Import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Drop the features 11 and 13\n","cc_apps = cc_apps.drop([11, 13], axis=1)\n","\n","# Split into train and test sets\n","cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"17"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_columns_dropped_correctly():\n","    assert cc_apps.shape == (\n","        690,\n","        14,\n","    ), \"The shape of the DataFrame isn't correct. Did you drop the two columns?\"\n","\n","\n","def test_data_split_correctly():\n","    cc_apps_train_correct, cc_apps_test_correct = train_test_split(\n","        cc_apps, test_size=0.33, random_state=42\n","    )\n","    assert cc_apps_train_correct.equals(cc_apps_train) and cc_apps_test_correct.equals(\n","        cc_apps_test\n","    ), \"It doesn't appear that the data splitting was done correctly.\""]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"dc":{"key":"24"},"tags":["sample_code"]},"outputs":[],"source":["# Import numpy\n","import numpy as np\n","\n","# Replace the '?'s with NaN in the train and test sets\n","cc_apps_train = cc_apps_train.replace('?', np.NaN)\n","cc_apps_test = cc_apps_test.replace('?', np.NaN)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"24"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","# def test_cc_apps_assigned():\n","#     assert \"cc_apps\" in globals(), \\\n","#         \"After the NaN replacement, it should be assigned to the same variable cc_apps only.\"\n","\n","\n","def test_cc_apps_correctly_replaced():\n","    cc_apps_fresh = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n","    cc_apps_train_correct, cc_apps_test_correct = train_test_split(\n","        cc_apps_fresh, test_size=0.33, random_state=42\n","    )\n","\n","    correct_cc_apps_replacement_correct_train = cc_apps_train_correct.replace(\n","        \"?\", np.NaN\n","    )\n","    correct_cc_apps_replacement_correct_test = cc_apps_test_correct.replace(\"?\", np.NaN)\n","    string_cc_apps_replacement_train = cc_apps_train_correct.replace(\"?\", \"NaN\")\n","    string_cc_apps_replacement_test = cc_apps_test_correct.replace(\"?\", \"NaN\")\n","    #     assert cc_apps.to_string() == correct_cc_apps_replacement.to_string(), \\\n","    #         \"The code that replaces question marks with NaNs doesn't appear to be correct.\"\n","    try:\n","        pd.testing.assert_frame_equal(\n","            correct_cc_apps_replacement_correct_train, cc_apps_train\n","        )\n","\n","        pd.testing.assert_frame_equal(\n","            correct_cc_apps_replacement_correct_test, cc_apps_test\n","        )\n","    except AssertionError:\n","        if string_cc_apps_replacement_train.equals(\n","            cc_apps_train\n","        ) or string_cc_apps_replacement_test.equals(cc_apps_test):\n","            assert (\n","                False\n","            ), 'It looks like the question marks were replaced by the string \"NaN\". Missing values should be represented by `np.nan`.'"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"31"},"tags":["sample_code"]},"outputs":[],"source":["# Impute the missing values with mean imputation\n","cc_apps_train.fillna(cc_apps_train.mean(), inplace=True)\n","cc_apps_test.fillna(cc_apps_train.mean(), inplace=True)\n","\n","# Count the number of NaNs in the datasets and print the counts to verify\n","print(cc_apps_train.isnull().sum())\n","print(cc_apps_test.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"31"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_cc_apps_correctly_imputed():\n","    assert (\n","        cc_apps_train.isnull().to_numpy().sum() == 39\n","        and cc_apps_test.isnull().to_numpy().sum() == 15\n","    ), \"There should be 39 and 15 null values in the training and test sets after your code is run, but there aren't.\""]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"38"},"tags":["sample_code"]},"outputs":[],"source":["# Iterate over each column of cc_apps_train\n","for col in cc_apps_train.columns:\n","    # Check if the column is of object type\n","    if cc_apps_train[col].dtypes == 'object':\n","        # Impute with the most frequent value\n","        cc_apps_train = cc_apps_train.fillna(cc_apps_train[col].value_counts().index[0])\n","        cc_apps_test = cc_apps_test.fillna(cc_apps_train[col].value_counts().index[0])\n","\n","# Count the number of NaNs in the dataset and print the counts to verify\n","print(cc_apps_train.isnull().sum())\n","print(cc_apps_test.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"38"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_cc_apps_correctly_imputed():\n","    assert (\n","        cc_apps_train.isnull().to_numpy().sum() == 0\n","        and cc_apps_test.isnull().to_numpy().sum() == 0\n","    ), \"There should be 0 null values after your code is run, but there isn't.\""]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"dc":{"key":"45"},"tags":["sample_code"]},"outputs":[],"source":["# Convert the categorical features in the train and test sets independently\n","cc_apps_train = pd.get_dummies(cc_apps_train)\n","cc_apps_test = pd.get_dummies(cc_apps_test)\n","\n","# Reindex the columns of the test set aligning with the train set\n","cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"45"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_label_encoding_done_correctly():\n","    for col in cc_apps_train.columns:\n","        if (\n","            np.issubdtype(cc_apps_train[col].dtype, np.number) != True\n","            and np.issubdtype(cc_apps_test[col].dtype, np.number) != True\n","        ):\n","            assert \"It doesn't appear that all of the non-numeric columns were converted to numeric using fit_transform and transform.\""]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"dc":{"key":"52"},"tags":["sample_code"]},"outputs":[],"source":["# Import MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Segregate features and labels into separate variables\n","X_train, y_train = cc_apps_train.iloc[:, :-1].values, cc_apps_train.iloc[:, [-1]].values\n","X_test, y_test = cc_apps_test.iloc[:, :-1].values, cc_apps_test.iloc[:, [-1]].values\n","\n","# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","rescaledX_train = scaler.fit_transform(X_train)\n","rescaledX_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"52"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_training_range_set_correctly():\n","    min_value_in_rescaledX_train = np.amin(rescaledX_train)\n","    max_value_in_rescaledX_train = np.amax(rescaledX_train)\n","    assert (\n","        min_value_in_rescaledX_train == 0.0 and max_value_in_rescaledX_train == 1.0\n","    ), \"Did you correctly fit and transform the `X_train` data?\"\n","\n","\n","def test_xtest_created():\n","    assert (\n","        \"rescaledX_test\" in globals()\n","    ), \"Did you correctly use the fitted `scaler` to transform the `X_test` data?\""]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"59"},"tags":["sample_code"]},"outputs":[],"source":["# Import LogisticRegression\n","from sklearn.linear_model import LogisticRegression\n","\n","# Instantiate a LogisticRegression classifier with default parameter values\n","logreg = LogisticRegression()\n","\n","# Fit logreg to the train set\n","logreg.fit(rescaledX_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"59"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_logreg_defined():\n","    assert (\n","        \"logreg\" in globals()\n","    ), \"Did you instantiate LogisticRegression in the logreg variable?\"\n","\n","\n","def test_logreg_defined_correctly():\n","    logreg_correct = LogisticRegression()\n","    assert str(logreg_correct) == str(\n","        logreg\n","    ), \"The logreg variable should be defined with LogisticRegression() only.\""]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"66"},"tags":["sample_code"]},"outputs":[],"source":["# Import confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","\n","# Use logreg to predict instances from the test set and store it\n","y_pred = logreg.predict(rescaledX_test)\n","\n","# Get the accuracy score of logreg model and print it\n","print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_test))\n","\n","# Print the confusion matrix of the logreg model\n","confusion_matrix(y_test,y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"66"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","def test_ypred_defined():\n","    assert \"y_pred\" in globals(),\\\n","        \"The variable y_pred should be defined.\"\n","\n","def test_ypred_defined_correctly():\n","    correct_y_pred = logreg.predict(rescaledX_test)\n","    assert str(correct_y_pred) == str(y_pred),\\\n","        \"The y_pred variable should contain the predictions as made by LogisticRegression on rescaledX_test.\""]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"dc":{"key":"73"},"tags":["sample_code"]},"outputs":[],"source":["# Import GridSearchCV\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the grid of values for tol and max_iter\n","tol = [0.01, 0.001 ,0.0001]\n","max_iter = [100, 150, 200]\n","\n","# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n","param_grid = dict(tol=tol, max_iter=max_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"73"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","\n","def test_tol_defined():\n","    assert \"tol\" in globals(), \"The variable tol should be defined.\"\n","\n","\n","def test_max_iter_defined():\n","    assert \"max_iter\" in globals(), \"The variable max_iter should be defined.\"\n","\n","\n","def test_tol_defined_correctly():\n","    correct_tol = [0.01, 0.001, 0.0001]\n","    assert (\n","        correct_tol == tol\n","    ), \"It looks like the tol variable is not defined with the list of correct values.\"\n","\n","\n","def test_max_iter_defined_correctly():\n","    correct_max_iter = [100, 150, 200]\n","    assert (\n","        correct_max_iter == max_iter\n","    ), \"It looks like the max_iter variable is not defined with a list of correct values.\"\n","\n","\n","def test_param_grid_defined():\n","    assert \"param_grid\" in globals(), \"The variable param_grid should be defined.\"\n","\n","\n","def test_param_grid_defined_correctly():\n","    correct_param_grid = dict(tol=tol, max_iter=max_iter)\n","    assert str(correct_param_grid) == str(\n","        param_grid\n","    ), \"It looks like the param_grid variable is not defined properly.\""]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"80"},"tags":["sample_code"]},"outputs":[],"source":["# Instantiate GridSearchCV with the required parameters\n","grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","\n","# Fit grid_model to the data\n","grid_model_result = grid_model.fit(rescaledX_train, y_train)\n","\n","# Summarize results\n","best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n","print(\"Best: %f using %s\" % (best_score, best_params))\n","\n","# Extract the best model and evaluate it on the test set\n","best_model = grid_model_result.best_estimator_\n","print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test,y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"80"},"hide":true,"tags":["tests"]},"outputs":[],"source":["%%nose\n","\n","correct_grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","correct_grid_model_result = correct_grid_model.fit(rescaledX_train, y_train)\n","\n","\n","def test_grid_model_defined():\n","    assert \"grid_model\" in globals(), \"The variable grid_model should be defined.\"\n","\n","\n","def test_grid_model_defined_correctly():\n","    # correct_grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","    assert str(correct_grid_model) == str(\n","        grid_model\n","    ), \"It doesn't appear that `grid_model` was defined correctly.\"\n","\n","\n","def test_grid_model_results_defined():\n","    assert (\n","        \"grid_model_result\" in globals()\n","    ), \"The variable `grid_model_result` should be defined.\"\n","\n","\n","def test_grid_model_result_defined_correctly():\n","    #     correct_grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","    #     correct_grid_model_result = correct_grid_model.fit(rescaledX, y)\n","    assert str(correct_grid_model_result) == str(\n","        grid_model_result\n","    ), \"It doesn't appear that `grid_model_result` was defined correctly.\"\n","\n","\n","def test_best_score_defined_correctly():\n","    #     correct_grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","    #     correct_grid_model_result = correct_grid_model.fit(rescaledX, y)\n","    correct_best_score = correct_grid_model_result.best_score_\n","    assert (\n","        correct_best_score == best_score\n","    ), \"It looks like the variable `best_score` is not defined correctly.\"\n","\n","\n","def test_best_params_defined_correctly():\n","    #     correct_grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","    #     correct_grid_model_result = correct_grid_model.fit(rescaledX, y)\n","    correct_best_params = correct_grid_model_result.best_params_\n","    assert (\n","        correct_best_params == best_params\n","    ), \"It looks like the variable `best_params` is not defined correctly.\"\n","\n","\n","def test_best_model_defined_correctly():\n","    correct_best_model = correct_grid_model_result.best_estimator_\n","    assert (\n","        str(correct_best_model) == str(best_model)\n","    ), \"It looks like the variable `best_model` is not defined correctly.\""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":2}
